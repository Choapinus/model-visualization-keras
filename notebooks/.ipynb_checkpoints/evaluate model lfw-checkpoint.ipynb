{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_path = '../dataset/lfw-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10269\n",
      "2966\n",
      "Alfred_Ford_0001.jpg\n",
      "\n",
      "Claudia_Coslovich_0001.jpg\n",
      "\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1]\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(13235,)\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(lfw_path)\n",
    "sorted(files)\n",
    "male, female = open(os.path.join(lfw_path, files[0]), 'r'), open(os.path.join(lfw_path, files[1]), 'r')\n",
    "lfw_dataset = os.path.join(lfw_path, files[-1])\n",
    "female, male = female.readlines(), male.readlines()\n",
    "\n",
    "# get list of images per class\n",
    "\n",
    "male_images, female_images = [], []\n",
    "\n",
    "for image_name_m in male:\n",
    "    attrs_m = image_name_m.split('_')[:-1]\n",
    "    folder_name_m = '_'.join(attrs_m)\n",
    "    image_path_m = os.path.join(lfw_dataset, folder_name_m, image_name_m)\n",
    "    \n",
    "    if '.jpg' not in image_path_m:\n",
    "        image_path_m = image_path_m.replace('\\n', '')\n",
    "        image_path_m += '.jpg'\n",
    "    \n",
    "    male_images.append(image_path_m.replace('\\n', ''))\n",
    "    \n",
    "for image_name_f in female:\n",
    "    attrs_f = image_name_f.split('_')[:-1]\n",
    "    folder_name_f = '_'.join(attrs_f)\n",
    "    image_path_f = os.path.join(lfw_dataset, folder_name_f, image_name_f)\n",
    "    \n",
    "    if '.jpg' not in image_path_f:\n",
    "        image_path_f = image_path_f.replace('\\n', '')\n",
    "        image_path_f += '.jpg'\n",
    "    female_images.append(image_path_f.replace('\\n', ''))\n",
    "\n",
    "dataset = {'female': female_images, 'male': male_images}\n",
    "\n",
    "print(male_images.__len__())\n",
    "print(female_images.__len__())\n",
    "print(male[0])\n",
    "print(female[0])\n",
    "male = [0]*len(male_images)\n",
    "female = [1]*len(female_images)\n",
    "print(male[:5])\n",
    "print(female[:5])\n",
    "y_true = np.array(male+female, dtype=int)\n",
    "print(y_true); print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] done!\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model('../models/lr_1e-3_last8_layers.h5')\n",
    "print(\"[INFO] done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image.astype('float') / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "preds = {'male': [], 'female': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length female: 2966\n",
      "[INFO] female done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pred female\n",
    "try:\n",
    "    print(\"length female: {}\".format(len(dataset['female'])))\n",
    "    for idx, image_name in enumerate(dataset['female']):\n",
    "        image = preprocess_image(image_name)\n",
    "        (female, male) = model.predict(image)[0]\n",
    "        label = 0 if male > female else 1\n",
    "        preds['female'].append(label)\n",
    "    #     print('female len: {}'.format(len(preds['female'])))\n",
    "#         print(idx, end=' ')\n",
    "    print(\"[INFO] female done\\n\")\n",
    "    \n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    print('id: {}'.format(idx))\n",
    "    print('name: {}'.format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length male: 10269\n",
      "OpenCV(3.4.4) /io/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "id: 10268\n",
      "name: /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/.jpg\n"
     ]
    }
   ],
   "source": [
    "# pred male\n",
    "try:\n",
    "    print(\"length male: {}\".format(len(dataset['male'])))\n",
    "    for idx, image_name in enumerate(dataset['male']):\n",
    "        image = preprocess_image(image_name)\n",
    "        (female, male) = model.predict(image)[0]\n",
    "        label = 0 if male > female else 1\n",
    "        preds['male'].append(label)\n",
    "    #     print('male len: {}'.format(len(preds['male'])))\n",
    "#         print(idx, end=' ')\n",
    "    print(\"[INFO] male done\")\n",
    "    \n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    print('id: {}'.format(idx))\n",
    "    print('name: {}'.format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total male: 10269\n",
      "wrong predictions of male: 85\n",
      "total female: 2966\n",
      "wrong predictions of female: 1513\n"
     ]
    }
   ],
   "source": [
    "wrong_m = 0\n",
    "wrong_f = 0\n",
    "wrong_m_list = []\n",
    "wrong_f_list = []\n",
    "\n",
    "for idx, pred in enumerate(preds['male']):\n",
    "    if pred == 1:\n",
    "        wrong_m += 1\n",
    "        wrong_m_list.append(idx)\n",
    "\n",
    "for idx, pred in enumerate(preds['female']):\n",
    "    if pred == 0:\n",
    "        wrong_f += 1\n",
    "        wrong_f_list.append(idx)\n",
    "\n",
    "print('total male: {}'.format(len(dataset['male'])))\n",
    "print('wrong predictions of male: {}'.format(wrong_m))\n",
    "\n",
    "print('total female: {}'.format(len(dataset['female'])))\n",
    "print('wrong predictions of female: {}'.format(wrong_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 23, 133, 219, 318, 490, 544, 680, 791, 826, 1183, 1201, 1287, 1461, 1615]\n",
      "[0, 1, 2, 3, 4, 6, 8, 9, 10, 13, 14, 15, 16, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "print(wrong_m_list[:15])\n",
    "print(wrong_f_list[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = preprocess_image(dataset['female'][17])\n",
    "# y = np.array([[1, 0]])\n",
    "\n",
    "# print(model.evaluate(X, y))\n",
    "# model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 1 1 1]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       male       0.87      0.99      0.93     10269\n",
      "     female       0.94      0.49      0.65      2966\n",
      "\n",
      "avg / total       0.89      0.88      0.86     13235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(preds['male']+preds['female']+[0], dtype=int)\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "\n",
    "target_names = ['male', 'female']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Tommy_Shane_Steiner/Tommy_Shane_Steiner_0001.jpg\n",
      "23 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Tristan_Gretzky/Tristan_Gretzky_0001.jpg\n",
      "133 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Ahmad_Masood/Ahmad_Masood_0001.jpg\n",
      "219 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Alberto_Acosta/Alberto_Acosta_0001.jpg\n",
      "318 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Alexandre_Herchcovitch/Alexandre_Herchcovitch_0001.jpg\n",
      "490 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Andy_Dick/Andy_Dick_0001.jpg\n",
      "544 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Anthony_Mazur/Anthony_Mazur_0001.jpg\n",
      "680 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Arminio_Fraga/Arminio_Fraga_0001.jpg\n",
      "791 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Atal_Bihari_Vajpayee/Atal_Bihari_Vajpayee_0021.jpg\n",
      "826 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Barry_Zito/Barry_Zito_0002.jpg\n",
      "1183 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Brandon_Boyd/Brandon_Boyd_0001.jpg\n",
      "1201 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Brendan_Hansen/Brendan_Hansen_0002.jpg\n",
      "1287 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Caio_Blat/Caio_Blat_0001.jpg\n",
      "1461 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Charlie_Coles/Charlie_Coles_0001.jpg\n",
      "1615 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Clint_Eastwood/Clint_Eastwood_0006.jpg\n"
     ]
    }
   ],
   "source": [
    "wrong_m_list = [22, 23, 133, 219, 318, 490, 544, 680, 791, 826, 1183, 1201, 1287, 1461, 1615]\n",
    "wrong_f_list = [0, 1, 2, 3, 4, 6, 8, 9, 10, 13, 14, 15, 16, 18, 19]\n",
    "\n",
    "for i in wrong_m_list:\n",
    "    print(i, '-', dataset['male'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Claudia_Coslovich/Claudia_Coslovich_0001.jpg\n",
      "1 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Allison_Searing/Allison_Searing_0001.jpg\n",
      "2 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Elizabeth_Hill/Elizabeth_Hill_0001.jpg\n",
      "3 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Erika_Reyes/Erika_Reyes_0001.jpg\n",
      "4 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Tatiana_Shchegoleva/Tatiana_Shchegoleva_0001.jpg\n",
      "6 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Adelina_Avila/Adelina_Avila_0001.jpg\n",
      "8 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Adriana_Perez_Navarro/Adriana_Perez_Navarro_0001.jpg\n",
      "9 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Adrianna_Zuzic/Adrianna_Zuzic_0001.jpg\n",
      "10 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Afton_Smith/Afton_Smith_0001.jpg\n",
      "13 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Ai_Sugiyama/Ai_Sugiyama_0001.jpg\n",
      "14 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Ai_Sugiyama/Ai_Sugiyama_0002.jpg\n",
      "15 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Ai_Sugiyama/Ai_Sugiyama_0003.jpg\n",
      "16 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Ai_Sugiyama/Ai_Sugiyama_0004.jpg\n",
      "18 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Ai_Sugiyama/Ai_Sugiyama_0005.jpg\n",
      "19 - /home/choppy/Desktop/CNN/visualization/dataset/lfw-dataset/lfw/Aicha_El_Ouafi/Aicha_El_Ouafi_0001.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in wrong_f_list:\n",
    "    print(i, '-', dataset['female'][i])\n",
    "# 6, 8, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
